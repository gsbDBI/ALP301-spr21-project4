---
title: "S2M_Split_into_new_old"
output: html_document
    highlight: haddock
    number_sections: no
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '2'
  pdf_document:
    toc: yes
    toc_depth: '2'
date: "April 2021"
---

```{r, message = FALSE, warning = FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse)
pacman::p_load(here)
pacman::p_load(lmtest)
pacman::p_load(glue)
pacman::p_load(broom)
pacman::p_load(ri2)
pacman::p_load(margins)
pacman::p_load(glmnet) 
pacman::p_load(kableExtra)
pacman::p_load(stargazer)
pacman::p_load(knitr)
pacman::p_load(doParallel)
pacman::p_load(corrplot)

rm(list = ls())

story_info<- read_csv("Datasets/all_story_obs.csv")
utility_mat<- read_csv("Datasets/utils_mat_filtered.csv",col_types = cols(.default = col_double()))
num_cols <- 2527
child_ids<-as.integer(utility_mat$child_id_code)
story_ids<-as.integer(colnames(utility_mat[,3:num_cols]))

#filter down from 2500+ stories to 1087 stories we have info on
stories_with_text<-(story_ids %in% story_info$story_id_code)
utility_matrix<-utility_mat[,3:num_cols]
utility_matrix<-utility_matrix[,stories_with_text]
story_ids<-colnames(utility_matrix)

#filter by number of "0" interactions because the opposite of that is interactions (.3, .5, 1). High 0 number means new user.
utility_matrix_old_activity <- utility_matrix[ which(rowSums(is.na(utility_matrix))<=1062),]
utility_matrix_new_activity <- utility_matrix[ which(rowSums(is.na(utility_matrix))>1062),]

#add 0s instead of NAs
utility_matrix_old_activity[is.na(utility_matrix_old_activity)]<-0.0
utility_matrix_new_activity[is.na(utility_matrix_new_activity)]<-0.0


```

```{r}

#check that filtering is working
mean(rowSums(utility_matrix_old_activity == 0))
mean(rowSums(utility_matrix_new_activity == 0))
summary(rowSums(utility_matrix_old_activity == 0))
summary(rowSums(utility_matrix_new_activity == 0))

#making old matrix
utility_matrix_old_activity<-as.matrix(utility_matrix_old_activity)

#making new matrix
utility_matrix_new_activity<-as.matrix(utility_matrix_new_activity)

rm(utility_mat)  # this variable is no longer needed
```

```{r}
source("../RecSys/get_item_scores.R", local = knitr::knit_global())
source("../RecSys/get_top_x_recommendations.R", local = knitr::knit_global())
source("../Utils/cross_validation_recsys.R", local = knitr::knit_global())
source("../Utils/save_recommender_results.R", local = knitr::knit_global())
source("../Utils/plot_diversity_recsys.R", local = knitr::knit_global())
source("../Utils/test_all_but_k.R", local = knitr::knit_global())
```

# ANALYSIS

OLD USERS

```{r old users create recs}
types <- c("random", "cbf", "svd", "ibcf")

params <- list(ibcf=list(),
               ubcf=list(),
               cbf=list(story_info=story_info, story_ids=story_ids),
               svd=list(d=20),
               random = list())

for (type in types) {
  cat("Type: ", type, "\n")
  cross_validation_recsys(utility_matrix=utility_matrix_old_activity,
                                   folds=10, X=5, type=type, key="old", params=params[[type]])
}

```

```{r}
precision_vector<-rep(NA,length(types))
recall_vector<-rep(NA,length(types))
rmse_vector<-rep(NA,length(types))
for (k in 1:length(types)) {
  results_type <- read_csv(paste("../Results/top_5_10_fold_cv_",types[k],"_old.csv", sep = ""))
  precision_vector[k] <- mean(results_type$precision.at.5)
  recall_vector[k] <- mean(results_type$recall.at.5)
  rmse_vector[k] <- mean(results_type$rmse)
}
results_df_old <- tibble(type=types, usage="old", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector)

ggplot(data = results_df_old) + 
  geom_point(mapping = aes(x = precision.at.5, y = recall.at.5,
                           size=rmse, color=type))

mean(results_df_old$precision.at.5)

```

```{r old users diversity}
params<-list()
item_scores<-get_item_scores_generator(utility_matrix, "random", params)
rm(params)
top_X_recommendations<-function(userid, X, ratings_matrix){
  get_top_x_recommendations(userid, X, ratings_matrix, SVD_item_scores)
}

recommender_fun_args <- list(ratings_matrix=utility_matrix, X=10)
filename = "rec_results_random_old.csv"
save_recommender_results(top_X_recommendations, recommender_fun_args, filename, full=TRUE)

rm(item_scores)
rm(top_X_recommendations)

plot_diversity_recsys("top_5_10_fold_cv_svd_old.csv")
plot_diversity_recsys("top_5_10_fold_cv_random_old.csv")
plot_diversity_recsys("top_5_10_fold_cv_ibcf_old.csv")
plot_diversity_recsys("top_5_10_fold_cv_cbf_old.csv")

```

```{r old users engagement metric}

```

NEW USERS

```{r new users create recs}
types <- c("random", "ibcf", "cbf", "svd")

params <- list(ibcf=list(),
               ubcf=list(),
               cbf=list(story_info=story_info, story_ids=story_ids),
               svd=list(d=20),
               random=list())

for (type in types) {
  cat("Type: ", type, "\n")
  cross_validation_recsys(utility_matrix=utility_matrix_new_activity,
                                   folds=10, X=5, type=type, key="new", params=params[[type]])
}

```

```{r new users all-but-k evaluation}

precision_vector<-rep(NA,length(types))
recall_vector<-rep(NA,length(types))
rmse_vector<-rep(NA,length(types))
for (k in 1:length(types)) {
  results_type <- read_csv(paste("../Results/top_5_10_fold_cv_",types[k],"_new.csv", sep = ""))
  precision_vector[k] <- mean(results_type$precision.at.5)
  recall_vector[k] <- mean(results_type$recall.at.5)
  rmse_vector[k] <- mean(results_type$rmse)
}
results_df_new <- tibble(type=types, usage="new", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector)

ggplot(data = results_df_new) + 
  geom_point(mapping = aes(x = precision.at.5, y = recall.at.5,
                           size=rmse, 
                           color=type))

random_rmse <- rmse_vector[1]
random_rmse
ibcf_rmse <- rmse_vector[2]
ibcf_rmse
cbf_rmse<- rmse_vector[3]
cbf_rmse
svd_rmse<- rmse_vector[4]
svd_rmse
```

```{r new users diversity}

```

```{r new users engagement metric}

```

