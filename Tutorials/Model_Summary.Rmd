---
title: "Model_Summary"
output: html_document
    highlight: haddock
    number_sections: no
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '2'
  pdf_document:
    toc: yes
    toc_depth: '2'
date: "April 2021"
---

```{r load packages and functions}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse)
pacman::p_load(here)
pacman::p_load(lmtest)
pacman::p_load(glue)
pacman::p_load(broom)
pacman::p_load(ri2)
pacman::p_load(margins)
pacman::p_load(glmnet) 
pacman::p_load(kableExtra)
pacman::p_load(stargazer)
pacman::p_load(knitr)
pacman::p_load(doParallel)
pacman::p_load(corrplot)
pacman::p_load(rsparse)
pacman::p_load(sqldf)
pacman::p_load(gridExtra)

rm(list = ls())

source("../RecSys/get_item_scores.R", local = knitr::knit_global())
source("../RecSys/get_top_x_recommendations.R", local = knitr::knit_global())
source("../Utils/cross_validation_recsys.R", local = knitr::knit_global())
source("../Utils/save_recommender_results.R", local = knitr::knit_global())
source("../Utils/plot_diversity_recsys.R", local = knitr::knit_global())
source("../Utils/test_all_but_k.R", local = knitr::knit_global())
source("../Utils/initialize_utility_matrix.R", local = knitr::knit_global())
source("../Utils/get_fm_parameters.R", local = knitr::knit_global())
source("../Utils/get_df_diversity.R", local = knitr::knit_global())
source("../Utils/engagement_function_only.R", local = knitr::knit_global())
```

```{r utility matrix setup}
story_info<- read_csv("Datasets/all_story_obs.csv")
utility_mat<- read_csv("Datasets/utils_mat_filtered.csv",col_types = cols(.default = col_double()))
rows<-sample(1:nrow(utility_mat),size=5000) # was 5000
utility_mat <- utility_mat[rows,]
num_cols <- 2527

# Set overall utility matrix
initialization <- initialize_utility_matrix(utility_mat, story_info, num_cols, fill_zero <- 0.0)
utility_matrix <- initialization$utility_matrix
story_ids <- initialization$story_ids
child_ids <- initialization$child_ids

# Create NA matrix
na_initialization <- initialize_utility_matrix(utility_mat, story_info, num_cols, fill_zero <- -999)
utility_matrix_na <- na_initialization$utility_matrix

# Create parameters for FM
params_fm <- get_fm_parameters(utility_mat, story_info, story_ids, child_ids)

```

# ANALYSIS

```{r analysis}
# Run Analysis  
# types <- c("fm", "svd", "cbf", "ubcf", "random", "ibcf") # Use for all models except ensemble
types <- c("ensemble") # Use for ensemble

params <- list(ibcf=list(),
ubcf=list(),
cbf=list(story_info=story_info, story_ids=story_ids),
svd=list(d=20),
random=list(),
fm=params_fm,
ensemble=list())

for (type in types) {
cat("Type: ", type, "\n")
cross_validation_recsys(utility_matrix=utility_matrix,
folds=10, X=5, type=type, key="overall", 
# params=params[[type]]) # Use for all models except ensemble
params=list()) # Use for ensemble
}


precision_vector<-rep(NA,length(types))
recall_vector<-rep(NA,length(types))
rmse_vector<-rep(NA,length(types))
for (k in 1:length(types)) {
results_type <- read_csv(paste("../Results/top_5_10_fold_cv_",types[k],"_overall.csv", sep = ""))
precision_vector[k] <- weighted.mean(results_type$precision.at.5, results_type$n)
recall_vector[k] <- weighted.mean(results_type$recall.at.5, results_type$n)
rmse_vector[k] <- weighted.mean(results_type$rmse, results_type$n)
}

# Use for all except ensemble
# results_df_other <- tibble(type=types, usage="overall", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector)

# Use for ensemble
results_df_ensemble <- tibble(type=types, usage="overall", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector)

```

```{r plot results}
# Combine results for all models
results_df <- rbind(results_df_other, results_df_ensemble)

# Plot
ggplot(data = results_df) + 
  geom_point(mapping = aes(x = precision.at.5, y = recall.at.5,
                           size=rmse, color=type))
```
```


# JOHANNA'S NEW CODE STARTS HERE
# SUBGROUP ANALYSIS

```{r subgroup matrices}

# CODE COPIED FROM LIBBY'S S2M_split_new_old.Rmd

story_info<- read_csv("Datasets/all_story_obs.csv")
utility_mat<- read_csv("Datasets/utils_mat_filtered.csv",col_types = cols(.default = col_double()))
num_cols <- 2527
child_ids<-as.integer(utility_mat$child_id_code)
story_ids<-as.integer(colnames(utility_mat[,3:num_cols]))

#filter down from 2500+ stories to 1087 stories we have info on
stories_with_text<-(story_ids %in% story_info$story_id_code)
utility_matrix<-utility_mat[,3:num_cols]
utility_matrix<-utility_matrix[,stories_with_text]
story_ids<-colnames(utility_matrix)

#filter by number of "0" interactions because the opposite of that is interactions (.3, .5, 1). High 0 number means new user.
utility_matrix_old_activity <- utility_matrix[ which(rowSums(is.na(utility_matrix))<=1062),]
utility_matrix_new_activity <- utility_matrix[ which(rowSums(is.na(utility_matrix))>1062),]

#add 0s instead of NAs
utility_matrix_old_activity[is.na(utility_matrix_old_activity)]<-0.0
utility_matrix_new_activity[is.na(utility_matrix_new_activity)]<-0.0
```

```{r}

# CODE COPIED FROM LIBBY'S S2M_split_new_old.Rmd

#check that filtering is working
mean(rowSums(utility_matrix_old_activity == 0))
mean(rowSums(utility_matrix_new_activity == 0))
summary(rowSums(utility_matrix_old_activity == 0))
summary(rowSums(utility_matrix_new_activity == 0))

#making old matrix
utility_matrix_old_activity<-as.matrix(utility_matrix_old_activity)

#making new matrix
utility_matrix_new_activity<-as.matrix(utility_matrix_new_activity)

rm(utility_mat)  # this variable is no longer needed
```

```{r params}
params <- list(ibcf=list(),
               ubcf=list(),
               cbf=list(story_info=story_info, story_ids=story_ids),
               svd=list(d=20),
               random=list(),
               fm=params_fm,
               ensemble=list())
```


```{r subgroup old}

# CODE COPIED FROM OVERALL ANALYSIS CHUNK ABOVE
# RUN THIS CODE CHUNK TWICE:
# (1) For all models except ensemble
# (2) For ensemble
# This requires commenting/uncommenting in 3 places below

# types <- c("fm", "svd", "cbf", "ubcf", "random", "ibcf") # Use for all except ensemble
types <- c("ensemble") # Use for ensemble

for (type in types) {
cat("Type: ", type, "\n")
cross_validation_recsys(utility_matrix=utility_matrix_old_activity,
folds=10, X=5, type=type, key="old", 
# params=params[[type]]) # Use for all models except ensemble
params=list()) # Use for ensemble
}


precision_vector<-rep(NA,length(types))
recall_vector<-rep(NA,length(types))
rmse_vector<-rep(NA,length(types))
for (k in 1:length(types)) {
results_type <- read_csv(paste("../Results/top_5_10_fold_cv_",types[k],"_old.csv", sep = ""))
precision_vector[k] <- weighted.mean(results_type$precision.at.5, results_type$n)
recall_vector[k] <- weighted.mean(results_type$recall.at.5, results_type$n)
rmse_vector[k] <- weighted.mean(results_type$rmse, results_type$n)
}

# Use for all except ensemble
# results_df_old_other <- tibble(type=types, usage="old", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector)

# Use for ensemble
results_df_old_ensemble <- tibble(type=types, usage="old", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector)

```

```{r subgroup new}

# CODE COPIED FROM OVERALL ANALYSIS CHUNK ABOVE
# RUN THIS CODE CHUNK TWICE:
# (1) For all models except ensemble
# (2) For ensemble
# This requires commenting/uncommenting in 3 places below

# types <- c("fm", "svd", "cbf", "ubcf", "random", "ibcf") # Use for all except ensemble
types <- c("ensemble") # Use for ensemble

for (type in types) {
cat("Type: ", type, "\n")
cross_validation_recsys(utility_matrix=utility_matrix_new_activity,
folds=10, X=5, type=type, key="new", 
# params=params[[type]]) # Use for all models except ensemble
params=list()) # Use for ensemble
}


precision_vector<-rep(NA,length(types))
recall_vector<-rep(NA,length(types))
rmse_vector<-rep(NA,length(types))
for (k in 1:length(types)) {
results_type <- read_csv(paste("../Results/top_5_10_fold_cv_",types[k],"_new.csv", sep = ""))
precision_vector[k] <- weighted.mean(results_type$precision.at.5, results_type$n)
recall_vector[k] <- weighted.mean(results_type$recall.at.5, results_type$n)
rmse_vector[k] <- weighted.mean(results_type$rmse, results_type$n)
}

# Use for all except ensemble
# results_df_new_other <- tibble(type=types, usage="new", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector)

# Use for ensemble
results_df_new_ensemble <- tibble(type=types, usage="new", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector)

```

```{r plot results}
# Combine ensemble with all other models
results_df_old <- rbind(results_df_old_ensemble, results_df_old_other)
results_df_new <- rbind(results_df_new_ensemble, results_df_new_other)

# Combine old and new
results_df <- rbind(results_df_old, results_df_new)
results_df$usage <- as.factor(results_df$usage)

# Plot
plot_old <- ggplot(data = results_df_old) + 
  geom_point(mapping = aes(x = precision.at.5, y = recall.at.5,
                           size=rmse, color=type)) +
  ggtitle("Old users") +
  xlim(0, 0.2) +
  ylim(0, 0.12)

plot_new <- ggplot(data = results_df_new) + 
  geom_point(mapping = aes(x = precision.at.5, y = recall.at.5,
                           size=rmse, color=type)) +
  ggtitle("New users") +
  xlim(0, 0.2) +
  ylim(0, 0.12)

grid.arrange(plot_old, plot_new, ncol=2)
```
# JOHANNA'S NEW CODE ENDS HERE

# DIVERSITY

```{r diversity}

for (type in types){

item_scores<-get_item_scores_generator(utility_matrix, type, params[[type]])
top_X_recommendations<-function(userid, X, ratings_matrix){
  get_top_x_recommendations(userid, X, ratings_matrix, item_scores)
}

recommender_fun_args <- list(ratings_matrix=utility_matrix, X=10)
filename <- paste("rec_results_",type,"_overall.csv", sep = "")
save_recommender_results(top_X_recommendations, recommender_fun_args, filename, full=TRUE)

df <- get_df_diversity(filename = filename, utility_matrix, unknown_value = 0.0)
assign(paste(type,"_df",sep = ""), df)
}

ggplot(df, aes(x, y = ..count.., fill = label)) +
    geom_density(color = "black", alpha = 0.5) +
    xlab("Number of readers") +
    ylab("Density") + 
    xlim(0, 1000)
```

```{r engagment}
engagement_types <- c("svd", "cbf", "ubcf", "ibcf")
engagement_types <- c("ibcf")
engagement_metric <- rep(NA,length(engagement_types))
for (i in 1:length(engagement_types)){
cat("Type: ", engagement_types[i], "\n")
engagement_metric[i] <- compute_engagement_metric(utility_matrix, utility_matrix_na, 500, engagement_types[i])

engagement_df <- tibble(type=engagement_types[i], engagement = engagement_metric[i])

if(i == 1){
engagement_total <- engagement_df[FALSE,]
}
engagement_total <- rbind(engagement_total, engagement_df)
}
```

```{r}
compute_engagement_metric(utility_matrix, utility_matrix_na, 500, "ibcf")
```


```{r simulation skeleton}
set.seed(123)

for (i in 1:2){
story_info<- read_csv("Datasets/all_story_obs.csv")
utility_mat<- read_csv("Datasets/utils_mat_filtered.csv",col_types = cols(.default = col_double()))
rows<-sample(1:nrow(utility_mat),size=3000)
utility_mat <- utility_mat[rows,]
num_cols <- 2527

# Set overall utility matrix
initialization <- initialize_utility_matrix(utility_mat, story_info, num_cols, fill_zero <- 0.0)
utility_matrix <- initialization$utility_matrix
story_ids <- initialization$story_ids
child_ids <- initialization$child_ids

# Create parameters for FM
params_fm <- get_fm_parameters(utility_mat, story_info, story_ids, child_ids)
  
# Run Analysis  
types <- c("fm", "svd", "cbf", "ubcf", "random", "ibcf")

params <- list(ibcf=list(),
ubcf=list(),
cbf=list(story_info=story_info, story_ids=story_ids),
svd=list(d=20),
random = list(),
fm=params_fm)

for (type in types) {
cat("Type: ", type, "\n")
cross_validation_recsys(utility_matrix=utility_matrix,
folds=10, X=5, type=type, key="overall", params=params[[type]])
}


precision_vector<-rep(NA,length(types))
recall_vector<-rep(NA,length(types))
rmse_vector<-rep(NA,length(types))
for (k in 1:length(types)) {
results_type <- read_csv(paste("../Results/top_5_10_fold_cv_",types[k],"_overall.csv", sep = ""))
precision_vector[k] <- weighted.mean(results_type$precision.at.5, results_type$n)
recall_vector[k] <- weighted.mean(results_type$recall.at.5, results_type$n)
rmse_vector[k] <- weighted.mean(results_type$rmse, results_type$n)
}

results_df <- tibble(type=types, usage="overall", precision.at.5=precision_vector, recall.at.5=recall_vector, rmse=rmse_vector, i)

if(i == 1){
results_total <- results_df[FALSE,]
}
results_total <- rbind(results_total, results_df)
}

```

