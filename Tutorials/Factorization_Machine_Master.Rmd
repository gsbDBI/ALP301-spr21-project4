---
title: 'Factorization Machine Code'
output:
  html_document:
    highlight: haddock
    number_sections: no
    theme: journal
    toc: yes
    toc_depth: 2
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '2'
  pdf_document:
    toc: yes
    toc_depth: '2'
date: "April 2021"
---

```{r setup, include=FALSE}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(tidyverse)
pacman::p_load(here)
pacman::p_load(lmtest)
pacman::p_load(glue)
pacman::p_load(broom)
pacman::p_load(ri2)
pacman::p_load(margins)
pacman::p_load(glmnet) 
pacman::p_load(kableExtra)
pacman::p_load(stargazer)
pacman::p_load(knitr)
pacman::p_load(doParallel)
pacman::p_load(corrplot)
pacman::p_load(corrplot)
pacman::p_load(rsparse)
pacman::p_load(recommenderlab)
pacman::p_load(reshape2)
pacman::p_load(ggplot2)

# rm(list = ls())

# Note for 2021 data (coverage: 2020-05-01 to 2021-01-31): 
## filter60 means that we filtered out interactions involving
# children who made fewer than 60 interactions;
# after filtering, there are 11202 users left.
# This applies to both utils_mat_filtered.csv and utils_raw_filter60.csv.

utility_mat<- read_csv("Datasets/utils_mat_filtered.csv",col_types = cols(.default = col_double()))
set.seed(1992)
rows<-sample(1:nrow(utility_mat),size=5000)
utility_mat <- utility_mat[rows, ]

user_mapping <- utility_mat[,1:2]

utils_raw_file <- "Datasets/utils_raw_filter60.csv"

# read story/user characteristics
story_info<- read_csv("Datasets/all_story_obs.csv")
user_info <- read_csv("Datasets/user_interests.csv")

# read utility matrix
utility_mat<- read_csv(utils_mat_file,col_types = cols(.default = col_double()))
utility_mat[is.na(utility_mat)]<-0.0

# read child-story interaction data
utility_data_raw<-read_csv(utils_raw_file,col_types = cols(.default = col_double()))

story_attr <- c("totpage","wordcount","story_id_code","n_people")
user_attr <- c("i_Life_skills","grade", "user_id")

params<-list(raw_matrix=utility_data_raw, story_info=story_info,
             user_info=user_info, story_attr=story_attr, user_attr=user_attr,
             model_type="gaussian", user_mapping = user_mapping)
```

Create initial function

```{r}
fm_get_factorization_matrix<-function(params){
  
  utility_data_raw <- params$raw_matrix%>% filter(!is.na(intensity))
  utility_data_raw <- utility_data_raw %>% rename(user_id = child_id_code)
  
  if(!is.null(params$story_info)){
  story_info <- story_info %>% select(one_of(params$story_attr))
  merged_data<-left_join(utility_data_raw, story_info, by = c("story_id_code"="story_id_code")) %>% drop_na 
  utility_data_raw <- merged_data
  }
  
  if(!is.null(params$user_info)){
  user_info <- params$user_info
  user_info$grade<-as.integer(str_extract(user_info$grade,"[1-9]"))
  user_info <- user_info %>% select(one_of(params$user_attr))
  merged_data<-left_join(utility_data_raw, user_info, by = c("user_id"="user_id")) %>% drop_na
  }
  merged_data
}

test_merged_data <- fm_get_factorization_matrix(params = params)

```

Testing 123

```{r}
fm_cleaned_dataset <- fm_get_factorization_matrix(params = params)
```

Next function
```{r}
fm_get_item_scores <- function(user_id, ratings_matrix, fm_cleaned_dataset, params){
# initialize model
factors <- append(params$story_attr, params$user_attr)
formula_fm <- as.formula(paste("intensity~", paste(factors, collapse="+")))
train_matrix <- model.matrix(formula_fm, data = fm_cleaned_dataset)
train_matrix_sparse = as(train_matrix, "RsparseMatrix")
if(params$model_type == "binomial"){
  train_outcome <-ifelse(fm_cleaned_dataset$intensity>0.4,1,0)
} else{
  train_outcome <- fm_cleaned_dataset$intensity
}
# run model
fm = FactorizationMachine$new(learning_rate_w = 0.06, rank = 15, lambda_w = 0.001,
lambda_v = 0.001, family = params$model_type, intercept = FALSE)
res = fm$fit(train_matrix_sparse, train_outcome, n_iter = 50)
fm_cleaned_dataset$preds = fm$predict(train_matrix)

# User Index Position
user_index <- params$user_mapping$child_id_code[params$user_mapping$X1 == user_id]

prediction_values <- fm_cleaned_dataset$preds[fm_cleaned_dataset$user_id==user_index]
story_positions <- fm_cleaned_dataset$story_id_code[fm_cleaned_dataset$user_id==user_index]

item_scores <- structure(prediction_values, names = as.character(story_positions))
filtered_item_scores <- item_scores[colnames(ratings_matrix)]
final_item_scores <- filtered_item_scores[!is.na(filtered_vectors) == TRUE]
final_item_scores
}
```

Try this function
```{r}
goal <- fm_get_item_scores(10, utility_matrix, fm_cleaned_dataset, params)
```

```{r}
set.seed(123)
source("../RecSys/get_item_scores.R", local = knitr::knit_global())
source("../RecSys/get_top_x_recommendations.R", local = knitr::knit_global())
FM_item_scores<-get_item_scores_generator(utility_matrix, "fm", params)
FM_top_X_recommendations<-function(userid, X, utility_matrix){
  get_top_x_recommendations(userid, X, utility_matrix, FM_item_scores)
}

recs<-FM_top_X_recommendations(10, 5, utility_matrix)
set.seed(123)
item_scores <- FM_item_scores(10, utility_matrix)
```


```{r}
  user_row<-utility_matrix[10,]
  unknown_stories<-user_row==0
  names_unknown<-story_ids[unknown_stories]
  unknown_stories_name <- names(unknown_stories[unknown_stories == TRUE])
  index <- which(item_scores[unknown_stories_name] >= sort(item_scores[unknown_stories_name], decreasing=T)[5], arr.ind=TRUE)
  
  names_unknown[index]

```
```{r}
unknown_stories_name <- names(unknown_stories[unknown_stories == TRUE])
  index <- which(item_scores[unknown_stories_name] >= sort(item_scores[unknown_stories_name], decreasing=T)[5], arr.ind=TRUE)
```

Note
```{r}
utility_mat<- read_csv("Datasets/utils_mat_filtered.csv",col_types = cols(.default = col_double()))
set.seed(1992)
rows<-sample(1:nrow(utility_mat),size=5000)
user_mapping <- utility_mat[,1:2]
```


Data Processing - this is the lever on how we will define the factorization machine

```{r info}

# filter out N/A entries
utility_data_raw%>% filter(!is.na(intensity))->utility_data_raw

# select story characteristics to be used
story_info %>% select(one_of(c("totpage","wordcount","story_id_code","n_people")))-> story_info_cut

# select user characteristics to be used
user_info %>% select(one_of(c("i_Life_skills","grade", "user_id")))-> user_info_cut


# combine story characteristics into the utility data
left_join(utility_data_raw, story_info_cut, by = c("story_id_code"="story_id_code")) %>% drop_na-> merged_data_all

# # combine user characteristics into the utility data
# left_join(merged_data_all, user_info_cut, by = c("child_id_code"="user_id")) %>% drop_na-> merged_data_all_user

# user_info[user_info$user_id == 547,]
# merged_data_all_user[merged_data_all_user$child_id_code == 71,]

# # split train/test data
# train_index<-sample(nrow(merged_data_all_user), floor(0.7*nrow(merged_data_all_user)))
# train_set<-merged_data_all_user[train_index,]
# test_set<-merged_data_all_user[-train_index,]
```

```{r model}

formula_fm<- intensity ~ totpage+wordcount+story_id_code+child_id_code+grade+n_people+i_Life_skills
train_matrix<-model.matrix(formula_fm, data = train_set)
train_matrix_sparse = as(train_matrix, "RsparseMatrix")

# If binary
train_outcome <-ifelse(train_set$intensity>0.4,1,0)
# If Gaussian
# train_outcome <-train_set$intensity
```

```{r run_model}
# create factorization machine model and train it - binomial

fm = FactorizationMachine$new(learning_rate_w = 0.03, rank = 50, lambda_w = 0.001,
lambda_v = 0.001, family = "binomial", intercept = FALSE)

# # create factorization machine model and train it - gaussian
# 
# fm = FactorizationMachine$new(learning_rate_w = 0.03, rank = 50, lambda_w = 0.001,
# lambda_v = 0.001, family = "gaussian", intercept = FALSE) 
# 
# Note this was originally 200
system.time({
  res = fm$fit(train_matrix_sparse, train_outcome, n_iter = 50)
  })


# If you run the model with the usual (0-0.3-0.5-1) encoding,
#truncate the predictions of the model
#so that anything below 0 is truncated to 0,
#and anything above 1 is truncated to 1.
preds = fm$predict(train_matrix)
sqrt(mean((train_outcome-preds)^2))
```


```{r}
source("../RecSys/get_item_scores.R", local = knitr::knit_global())
source("../RecSys/get_top_x_recommendations.R", local = knitr::knit_global())

All_Item_Scores_IBCF<-get_item_scores_generator(utility_matrix, "ibcf")

Item_based_top_X_recommendations<-function(userid, X, utility_matrix){
  get_top_x_recommendations(userid, X, utility_matrix, All_Item_Scores_IBCF)
}
#Top five recommendations to user 100
recs<-Item_based_top_X_recommendations(100, 5, utility_matrix)

similarity_matrix_item <- ibcf_get_similarity_matrix(utility_matrix)

 # similarity_matrix_item <- ibcf_get_similarity_matrix(utility_matrix)
 #    return(
 #      function(userid, ratings_matrix){
 #        ibcf_get_item_scores(userid, ratings_matrix, similarity_matrix_item)
 #      }

```

